{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils #thru the pip package.\n",
    "# from skimage.filters import threshold_adaptive\n",
    "import gtk, pygtk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some globals -\n",
    "window = gtk.Window()\n",
    "screen = window.get_screen()\n",
    "# for positioning image windows\n",
    "windowX,windowY = 0,0 \n",
    "windowWidth = screen.get_width()\n",
    "windowHeight = screen.get_height()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toolbox functions-\n",
    "# cv2.createTrackbar('boxDim', 'ImageWindow', 2000, 5000, someFunctionCallBack)\n",
    "\n",
    "def waitQ():\n",
    "    while(cv2.waitKey(1)& 0xFF != ord('q')):pass\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def show(name,img,pause=1,resetpos=None):\n",
    "    global windowX\n",
    "    global windowY\n",
    "    if(type(img)== type(None)):\n",
    "        print(name,\" NoneType image to show!\")\n",
    "        if(pause):\n",
    "#             debug = input()\n",
    "            cv2.destroyAllWindows()\n",
    "        return\n",
    "    cv2.imshow(name,img)\n",
    "    \n",
    "    w,h,_ = img.shape\n",
    "    if(resetpos):\n",
    "        windowX=resetpos[0]\n",
    "        windowY=resetpos[1]\n",
    "    cv2.moveWindow(name,windowX,windowY)\n",
    "    overflowX = windowX+w > windowWidth\n",
    "    overflowY = windowY+h > windowHeight\n",
    "    if(overflowX):\n",
    "        windowX = 0\n",
    "        if(not overflowY):windowY+=h\n",
    "    else:windowX+=w\n",
    "    if(overflowY):windowY = 0\n",
    "    if(pause):\n",
    "        waitQ()\n",
    "    \n",
    "def myColor1():\n",
    "    return (randint(100,250),randint(100,250),randint(100,250))\n",
    "def order_points(pts):\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\n",
    "\t# compute the width of the new image, which will be the\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "\t# return the warped image\n",
    "\treturn warped\n",
    "    \n",
    "\n",
    "def readResponse(pts,boxDim,img,threshold=0.5,bord=-1,white=(220,220,220),black=(0,0,0)):\n",
    "    _, t = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "    w,h=boxDim\n",
    "    mask = 255*np.ones(boxDim, np.uint8)\n",
    "    ret = {}\n",
    "    for pt in pts:\n",
    "        pt = tuple(map(int,pt))\n",
    "        x,y=pt \n",
    "        crop=img[y:y+h,x:x+w]\n",
    "        mean_color = cv2.mean(crop,mask)\n",
    "        ret[pt]= mean_color[0]/255#\n",
    "        clr = black if threshold > mean_color[0]/255 else white\n",
    "        cv2.rectangle(img,pt,(x+w,y+h),clr,bord)#-1 is for fill\n",
    "    return ret\n",
    "def calcGaps(PointsX,PointsY,numsX,numsY):\n",
    "    gapsX = ( abs(PointsX[0]-PointsX[1])/(numsX[0]-1),abs(PointsX[2]-PointsX[3]) )\n",
    "    gapsY = ( abs(PointsY[0]-PointsY[1])/(numsY[0]-1),abs(PointsY[2]-PointsY[3]) )\n",
    "    return (gapsX,gapsY)\n",
    "\n",
    "def maketemplate(start,numsX,numsY,gapsX,gapsY):\n",
    "    templateMCQ=[]\n",
    "    posx=start[0]\n",
    "    for x in range(numsX[1]):\n",
    "        posy=start[1]\n",
    "        for y in range(numsY[1]):\n",
    "            templateMCQ.append((posx,posy))\n",
    "            posy+= (gapsY[1] if ((y+1) % numsY[0]==0) else gapsY[0])\n",
    "        posx+= (gapsX[1] if ((x+1) % numsX[0]==0) else gapsX[0])\n",
    "    return templateMCQ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmouse_and_match - template matching\\nlk_track - draw in the air\\nlk_homography - see good features\\ngabor_threads - that fantasy tiger wallpaper\\nfloodfill -> That paint bucket is this one\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good ones from opencv SAMPLES -\n",
    "\"\"\"\n",
    "mouse_and_match - template matching\n",
    "lk_track - draw in the air\n",
    "lk_homography - see good features\n",
    "gabor_threads - that fantasy tiger wallpaper\n",
    "floodfill -> That paint bucket is this one\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 1.5, 0.5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[0.5,1.5,0,1,3,5,6]\n",
    "map(int,np.multiply(a,10))\n",
    "a = [a,a]\n",
    "pts = [[0,1],[1,0],[1,5],[0,5]]\n",
    "map(lambda x:a[x[0]][x[1]],sorted(pts,key=lambda pt: a[pt[0]][pt[1]],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(p1,p2):\n",
    "    return np.linalg.norm(np.array(p1)-np.array(p2))\n",
    "def getslope(pt1,pt2):\n",
    "    return float(pt2[1]-pt1[1])/float(pt2[0]-pt1[0])\n",
    "def check_min_dist(pt,pts,min_dist):\n",
    "    for p in pts:\n",
    "        if(dist(pt,p) < min_dist):\n",
    "            return False\n",
    "    return True\n",
    "        \n",
    "\n",
    "def get_reflection(pt, pt1,pt2):\n",
    "    pt, pt1,pt2 = map(lambda x:np.array(x,dtype=float),[pt, pt1,pt2])\n",
    "    return (pt1 + pt2) - pt\n",
    "def printbuf(x):\n",
    "    sys.stdout.write(str(x))\n",
    "    sys.stdout.write('\\r')\n",
    "\n",
    "def someFunctionCallBack(*arg):\n",
    "    readResponse(pts,(boxDimX,boxDimY),img,threshold=0.55,bord=-1)\n",
    "\n",
    "def match_template_scaled(img1, template,show_detected=False,pts=4,\n",
    "                          scaleRange=(0.5,1.5),fac=100,min_dist=None,threshold=0.6,\n",
    "                          CLR=(0,255,255),iterLim=30,excludepts=None):\n",
    "    orig=template.copy()\n",
    "    w1,h1,_=img1.shape\n",
    "    w,h,_=template.shape\n",
    "    if( not min_dist):\n",
    "        min_dist = h1/10\n",
    "    scale=float(h1)/h\n",
    "    print('initial scale',scale)\n",
    "    x=map(int,np.multiply(scaleRange,fac))\n",
    "    if((x[1]-x[0])> iterLim*fac/10):\n",
    "        print(\"Too many iterations : %d, reduce scaleRange\" % ((x[1]-x[0])*10/fac) )\n",
    "        return []\n",
    "    r_max=None\n",
    "    for r0 in range(x[0],x[1],fac/10):\n",
    "        r=float(r0)/fac\n",
    "        printbuf(r)\n",
    "        if(r==0.0):\n",
    "            continue\n",
    "        templ = imutils.resize(orig, height = int(h*r))\n",
    "        res = cv2.matchTemplate(img1,templ,cv2.TM_CCOEFF_NORMED)\n",
    "#         cv2.imshow('res',res)        waitQ()\n",
    "        maxT = res.max()\n",
    "        if(threshold < maxT):\n",
    "            printbuf(' %d )Better match %d%%' % (r0,100*maxT))\n",
    "            r_max=r\n",
    "            threshold = maxT\n",
    "    if(r_max==None):\n",
    "        print(\"No matchings for given threshold & scaleRange\")\n",
    "        return []\n",
    "    print('')\n",
    "    print('final scale',r_max)\n",
    "    templ = imutils.resize(orig, height = int(h*r_max))\n",
    "    res = cv2.matchTemplate(img1,templ,cv2.TM_CCOEFF_NORMED)# better than TM_CCOEFF_NORMED)\n",
    "#     show('res',res)    \n",
    "    #Set threshold of top four points - \n",
    "    #argpartition : kth point will be in its sorted position i.e. k, others will be 'partitioned'\n",
    "    res2  =  res.flatten() # serial threshold values.\n",
    "    partitioned_res2=np.argpartition(a = res2,kth = -pts*2)\n",
    "    threshold = min(res2[partitioned_res2[-pts*2:]])\n",
    "\n",
    "#     NOW DISCARD NEARBY POINTS\n",
    "    loc = np.where(res>=threshold) # now this already gives only pts*2 points\n",
    "    locs = zip(*loc[::-1])\n",
    "#     Now just order them by res values\n",
    "    locs = sorted(locs,key=lambda pt: res[pt[1]][pt[0]],reverse=True)\n",
    "    w,h,_=templ.shape\n",
    "    centres=[]\n",
    "    i=0\n",
    "\n",
    "    exclude = type(excludepts)!=type(None)\n",
    "    \n",
    "    for pt in locs: #zipped because it gives Xs and Ys seperated & probab ordered by Xs\n",
    "        if(i==pts):\n",
    "            break\n",
    "        if(check_min_dist(pt,centres,min_dist) or (exclude and check_min_dist(pt,excludepts,min_dist))):\n",
    "            cv2.rectangle(img1,pt,(pt[0]+w,pt[1]+h),CLR,2)\n",
    "            centres.append([pt[0]+w/2,pt[1]+h/2])\n",
    "            i+=1\n",
    "        else:\n",
    "            print('skipped nearby point', pt,min_dist,centres,excludepts)\n",
    "        \n",
    "    if(show_detected):\n",
    "        show('detected',img1)    \n",
    "    return np.array(centres)\n",
    "\n",
    "def get_fourth_pt(three_pts):\n",
    "    m=[]\n",
    "    # \tof the three points, two form a diagonal, third one can be found by-\n",
    "#         1. Angle estimate : In the triangle, choose the one having near 90 degrees and add its reflection\n",
    "#         2. Slope estimation-\n",
    "#         3. Distance calc\n",
    "\n",
    "    for i in range(3):\n",
    "        m.append(dist(three_pts[i],three_pts[(i+1)%3]))\n",
    "        \n",
    "    v =max(m)\n",
    "    for i in range(3):\n",
    "        if(m[i]!=v and m[(i+1)%3]!=v):\n",
    "            refl = (i+1) % 3\n",
    "            break\n",
    "    fourth_pt = get_reflection( three_pts[refl],three_pts[(refl+1)%3],three_pts[(refl+2)%3])\n",
    "    return fourth_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Wrapper\n",
    "def getROI(orig,templ,excludetempl=None,verbose=False,pts=3,scaleRange=(0.25,1.5),fac=100,threshold=0.55,iterLim=50):\n",
    "    template=templ.copy()\n",
    "    image=orig.copy()\n",
    "    image=image-cv2.erode(image,None)\n",
    "    template=template-cv2.erode(template,None)\n",
    "    excludepts=None\n",
    "    if( type(excludetempl) != type(None)):\n",
    "        excludetempl=excludetempl-cv2.erode(excludetempl,None)\n",
    "        excludepts = match_template_scaled(image,excludetempl,\n",
    "                                show_detected=verbose,\n",
    "                                pts=1,\n",
    "                                scaleRange=scaleRange,fac=fac,threshold=threshold,iterLim=iterLim)\n",
    "        print(\"lon location : \",excludepts)\n",
    "    \n",
    "        \n",
    "    \n",
    "    # cv2.createTrackbar('boxDim', 'ImageWindow', 2000, 5000, match_template_scaled_with_time_flag)\n",
    "    four_pts =match_template_scaled(image,template,\n",
    "                                show_detected=verbose,\n",
    "                                pts=pts,\n",
    "                                scaleRange=scaleRange,fac=fac,threshold=threshold,iterLim=iterLim,excludepts=excludepts)\n",
    "    if(pts == 3 and len(four_pts)==3):\n",
    "        three_pts=four_pts\n",
    "        four_pts = np.concatenate([four_pts,[get_fourth_pt(three_pts)]])\n",
    "\n",
    "    if(verbose):\n",
    "        print(four_pts)\n",
    "    if(len(four_pts)>=4):\n",
    "        warped = four_point_transform(orig, four_pts)\n",
    "        return warped        \n",
    "    else:\n",
    "        print(\"Unable to find enough points!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How about cropping out top 5% and bottom 25% part of the input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windowX,windowY = 0,0 \n",
    "uniform_height = 1000\n",
    "template = cv2.imread('FinalCircle.png') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "lontemplate = cv2.imread('lontemplate.jpg') \n",
    "# orig = cv2.imread('practiOMR.jpg') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "# orig2 = cv2.imread('practiOMR2.jpg') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "# orig = imutils.resize(orig,height=uniform_height)\n",
    "# orig2 = imutils.resize(orig2,height=uniform_height)\n",
    "\n",
    "# warped = getROI(orig,template,scaleRange=(0.75,1.5))\n",
    "# show('cropped',warped,0)\n",
    "# warped2 = getROI(orig2,template,scaleRange=(0.75,1.5))\n",
    "# show('cropped2',warped2,0)\n",
    "\n",
    "for i in range(1,36):\n",
    "    sample3 = cv2.imread('realsamples/sample'+str(i)) \n",
    "    sample3 = imutils.resize(sample3,height=uniform_height)\n",
    "    sample3crop = getROI(sample3,template,scaleRange=(0.75,1.5))\n",
    "    show('sample'+str(i),sample3crop)\n",
    "    \n",
    "\n",
    "#Getting Wrong Crops? - Keep checking with the scales\n",
    "\n",
    "# warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a15d5c8424df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# image was grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarped\u001b[0m\u001b[0;31m#np.zeros(warped.shape, np.uint8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warped' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now dvlpments-\n",
    "If multi-marked, try lower threshold, if still get multiple dark, move on, else choose the most dark one.\n",
    "Make a questions class - It has options & their (4 by default) coordinates\n",
    "pass array of questions to readResponse : it just reads the coords and updates whether its marked or not.\n",
    "\n",
    "\"\"\"\n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "fx,fy = -1,-1\n",
    "erase= True\n",
    "\n",
    "# mouse callback function\n",
    "def draw_rect(event,x,y,flags,param):\n",
    "    global ix,iy,fx,fy,drawing,mode,mask\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            cv2.rectangle(mask,(ix,iy),(x,y),(0,0,0),-1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if(erase):\n",
    "            mask = np.zeros_like(mask)\n",
    "        print(\"(%d,%d) : (%d,%d)\" % (ix,iy,x,y))\n",
    "        cv2.putText(mask,(\"(%d,%d) : (%d,%d)\" % (ix,iy,x,y)),(10,30),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.0,(0,250,100),2)\n",
    "        fx,fy=x,y\n",
    "        cv2.rectangle(mask,(ix,iy),(fx,fy),(0,0,0),-1)\n",
    "# image was grayscale\n",
    "img = warped#np.zeros(warped.shape, np.uint8)\n",
    "mask = np.zeros(img.shape, np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_rect)\n",
    "pts1=[]\n",
    "pts2=[]\n",
    "while(1):\n",
    "    cv2.imshow('image',cv2.subtract(img,mask))\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('x'):\n",
    "        print(\"Erase\",erase)\n",
    "        erase=not erase\n",
    "        \n",
    "    elif k == ord('a'):\n",
    "        pt1,pt2=(ix,iy),(fx,fy)        \n",
    "        print(\"added\",pt1,pt2)\n",
    "        pts1.append(pt1)\n",
    "        pts2.append(pt2)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pt1,pt2=np.array(pts1).mean(),np.array(pts2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktempl(pX,pY,divsX,divsY):\n",
    "    gapsX,gapsY=calcGaps(pX,pY,nX,nY)\n",
    "    return maketemplate((pX[0],pY[0]),nX,nY,gapsX,gapsY)\n",
    "\n",
    "img = cv2.imread('technoOMR_marked.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    "h,w =img.shape\n",
    "PointsX,PointsY = (38,92,92,118.75),(352,388,388,406.25)\n",
    "gapsX,gapsY=calcGaps(PointsX,PointsY,(4,20),(5,20))\n",
    "print(gapsX,gapsY)\n",
    "# PointsX will have only x coords of the horiz points\n",
    "t=mktempl(PointsX,PointsY,divsX=(4,20),divsY=(5,20))\n",
    "g1,g2=calcGaps((265,282,282,310),(236,317,236,317),(2,4),(10,10))\n",
    "t1=maketemplate((265,236),(2,4),(10,10),g1,g2)\n",
    "t2=maketemplate((355,236),(2,4),(10,10),(g1[0]*1.13,g1[0]),g2)\n",
    "t3=maketemplate((355,236),(2,4),(10,10),(g1[0]*1.13,g1[0]),g2)\n",
    "# t3=maketemplate((30,90),(25,25),(26,26),(9,9),PointsY)\n",
    "pts=t+t1+t2\n",
    "boxDimX,boxDimY=(6,6)\n",
    "readResponse(pts,(boxDimX,boxDimY),img,threshold=0.55,bord=-1)\n",
    "cv2.imshow('imageWindow',img)\n",
    "# cv2.createTrackbar('boxDimY', 'imageWindow', 6, 10, someFunctionCallBack)\n",
    "\n",
    "waitQ()\n",
    "\"\"\"\n",
    "Note : You'll get this error if the code is accessing pixels out of bounds of the image\n",
    "error: (-215) A.size == arrays[i0]->size in function init\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pseudo code- Sound and Simple\n",
    "Image processing to :\n",
    "    Done using getPerspectiveTransform> Scale and rotate image correctly\n",
    "    Detect responses correctly-\n",
    "        Check if bubble size bigger than threshold\n",
    "    Return the response to each question in a list.\n",
    "Pure python to :\n",
    "    Check the answers\n",
    "    Provide a GUI ? (tkinker)\n",
    "    >Web interface preferred\n",
    "    \n",
    "    \n",
    "But first, get going with a static template and read the color\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('OMRMarked.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    " \n",
    "#---- 4 corner points of the bounding box\n",
    "pts_src = np.array([[17.0,0.0], [77.0,5.0], [0.0, 552.0],[53.0, 552.0]])\n",
    "\n",
    "#---- 4 corner points of the black image you want to impose it on\n",
    "pts_dst = np.array([[0.0,0.0],[77.0, 0.0],[ 0.0,552.0],[77.0, 552.0]])\n",
    "\n",
    "#---- forming the black image of specific size\n",
    "im_dst = np.zeros((552, 77, 3), np.uint8)\n",
    "\n",
    "#---- Framing the homography matrix\n",
    "h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "#---- transforming the image bound in the rectangle to straighten\n",
    "im_out = cv2.warpPerspective(img, h, (im_dst.shape[1],im_dst.shape[0]))\n",
    "cv2.imshow(\"im_out.jpg\", im_out)\n",
    "waitQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#underscore consumes the variable - retval here\n",
    "img = cv2.imread('OMRSample.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    "#retval, threshold = cv2.threshold(img,signumThrVal,maxVal,cv2.THRESH_BINARY_INV)\n",
    "threshold=[]\n",
    "_, t = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "threshold.append(t)\n",
    "threshold.append(cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1))\n",
    "ret, t = cv2.threshold(img,126,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "threshold.append(t)\n",
    "cv2.imshow('imageWindow',img)\n",
    "\n",
    "for i in range(0,3):\n",
    "    cv2.imshow('th'+str(i),threshold[i]);\n",
    "    cv2.moveWindow('th'+str(i),1280,0)\n",
    "\n",
    "waitQ()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cam Scanner Code \n",
    "image = cv2.imread('OMRTemp.jpg') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    " \n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "# show the original image and the edge detected image\n",
    "# print \"STEP 1: Edge Detection\"\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "waitQ()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "# try mode= CV_RETR_EXTERNAL \n",
    "_ , cnts ,_ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#The hack -\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:min(5,len(cnts))] # get top 5 largest contours by area\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "\t# if our approximated contour has four points, then we\n",
    "\t# can assume that we have found our screen\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\tbreak\n",
    "\n",
    "# show the contour (outline) of the piece of paper\n",
    "print \"STEP 2: Find contours of paper\"\n",
    "cv2.drawContours(image, [screenCnt], -1, (244, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "# warped = threshold_adaptive(warped, 251, offset = 10)\n",
    "# warped = cv2.adaptiveThreshold(warped,25,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "warped = warped.astype(\"uint8\") * 255\n",
    " \n",
    "# show the original and scanned images\n",
    "print \"STEP 3: Apply perspective transform\"\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "waitQ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Template Matching Code-\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('technoOMR_marked.jpg',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('circle.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img,top_left, bottom_right, 0, 2)\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    \n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
