{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad03ce33-7a5b-4001-a332-a3e5caf9d82b",
   "metadata": {},
   "source": [
    "#Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec46a412-c575-44ff-9e66-5e42cc58d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "marker_rescale_range =  (35, 100)\n",
    "marker_rescale_steps =  10\n",
    "def order_points(pts):\n",
    "        rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "        # the top-left point will have the smallest sum, whereas\n",
    "        # the bottom-right point will have the largest sum\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]\n",
    "        rect[2] = pts[np.argmax(s)]\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]\n",
    "        rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "        # return the ordered coordinates\n",
    "        return rect\n",
    "    #used this fucthon to crop based four point of four side of paper that devide based maker\n",
    "def four_point_transform(image, pts):\n",
    "        # obtain a consistent order of the points and unpack them\n",
    "        # individually\n",
    "\n",
    "        rect = order_points(pts)\n",
    "        (tl, tr, br, bl) = rect\n",
    "\n",
    "        # compute the width of the new image, which will be the\n",
    "        width_a = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        width_b = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\n",
    "        max_width = max(int(width_a), int(width_b))\n",
    "        # max_width = max(int(np.linalg.norm(br-bl)), int(np.linalg.norm(tr-tl)))\n",
    "\n",
    "        # compute the height of the new image, which will be the\n",
    "        height_a = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        height_b = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        max_height = max(int(height_a), int(height_b))\n",
    "        # max_height = max(int(np.linalg.norm(tr-br)), int(np.linalg.norm(tl-br)))\n",
    "\n",
    "        # now that we have the dimensions of the new image, construct\n",
    "        # the set of destination points to obtain a \"birds eye view\",\n",
    "        # (i.e. top-down view) of the image, again specifying points\n",
    "        # in the top-left, top-right, bottom-right, and bottom-left\n",
    "        # order\n",
    "        dst = np.array(\n",
    "            [\n",
    "                [0, 0],\n",
    "                [max_width - 1, 0],\n",
    "                [max_width - 1, max_height - 1],\n",
    "                [0, max_height - 1],\n",
    "            ],\n",
    "            dtype=\"float32\",\n",
    "        )\n",
    "\n",
    "        transform_matrix = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, transform_matrix, (max_width, max_height))\n",
    "\n",
    "        # return the warped image\n",
    "        return warped\n",
    "def normalize_util(img, alpha=0, beta=255):\n",
    "        return cv2.normalize(img, alpha, beta, norm_type=cv2.NORM_MINMAX)\n",
    "def resize_util_h(img, u_height, u_width=None):\n",
    "            if u_width is None:\n",
    "                h, w = img.shape[:2]\n",
    "                u_width = int(w * u_height / h)\n",
    "            return cv2.resize(img, (int(u_width), int(u_height)))    \n",
    "def resize_util(img, u_width, u_height=None):\n",
    "            if u_height is None:\n",
    "                h, w = img.shape[:2]\n",
    "                u_height = int(h * u_width / w)\n",
    "            return cv2.resize(img, (int(u_width), int(u_height)))\n",
    "marker = cv2.imread(\"savedmar.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "def getBestMatch(image_eroded_sub):\n",
    "            cv2.imwrite('image_eroded_sub.jpg', image_eroded_sub)    \n",
    "            descent_per_step = (\n",
    "                marker_rescale_range[1] - marker_rescale_range[0]\n",
    "            ) // marker_rescale_steps\n",
    "\n",
    "            _h, _w = marker.shape[:2]\n",
    "            res, best_scale = None, None\n",
    "            all_max_t = 0\n",
    "\n",
    "            for r0 in np.arange(marker_rescale_range[1],marker_rescale_range[0],-1 * descent_per_step,):  # reverse order\n",
    "                s = float(r0 * 1 / 100)\n",
    "                if s == 0.0:\n",
    "                    continue\n",
    "                rescaled_marker = resize_util_h(marker, u_height=int(_h * s))\n",
    "                # res is the black image with white dots\n",
    "                res = cv2.matchTemplate(image_eroded_sub, rescaled_marker, cv2.TM_CCOEFF_NORMED )\n",
    "                # cv2.imshow(str(5+r0),res)\n",
    "                max_t = res.max()\n",
    "                if all_max_t < max_t:\n",
    "                   # print(\"-------------------------------------------------------------\\n\")\n",
    "                    #print('Scale: '+str(s)+', Circle Match: '+str(round(max_t*100,2))+'%')\n",
    "                    #print(\"-------------------------------------------------------------\\n\")\n",
    "                    best_scale, all_max_t = s, max_t\n",
    "            return best_scale, all_max_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e816d5b-6274-44cc-b26f-d9c5cd9fdcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fedc429-42fd-4fd2-a59d-c4302df7fa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
